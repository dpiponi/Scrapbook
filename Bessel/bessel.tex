\documentclass{article}
\usepackage{mathtools}
\usepackage{pgf}
\usepackage{tikz}
\usepackage{mathdots}
\usepackage{amsfonts}
\usetikzlibrary{arrows,automata,decorations.markings}
\makeatletter
\newcommand\mathcircled[1]{%
  \mathpalette\@mathcircled{#1}%
}
\newcommand\@mathcircled[2]{%
  \tikz[baseline=(math.base)] \node[draw,circle,inner sep=1pt] (math) {$\m@th#1#2$};%
}
\newcommand\myvec[1]{\vec{#1}\hspace{0.5mm}}
\makeatother

% TODO
% More motivation with trig and elliptic examples
% More on C
% Better notation for T, R and C
% Some blurb about f(x,y) = f(r,\theta) = f(z) = f(\myvec{p})
% Some plots

\begin{document}
\section{Introduction}
Many transcendental functions have associated addition formulae.
For example
\begin{align}
\cos(\theta+\phi) & = \cos(\theta)\cos(\phi)-\sin(\theta)\sin(\phi) \label{cos} \\
\tan(\theta+\phi) &= \frac{\tan\theta+\tan\phi}{1-\tan\theta\tan\phi} \label{tan} \\
\log x+\log y &= \log(xy) \label{log}
\end{align}
and there are more complex addition formulae for the elliptic functions.
All of these examples arise from group structures.
For example, Equation~(\ref{log}) is essentially a statement of the fact that we have a homomorphism from the group $(\mathbb{R},+)$ to $(\mathbb{R}^+,\times)$ given by the function $\exp$ (of which $\log$ is the inverse).
Equations~(\ref{cos}) and (\ref{tan}) come from the homomorphism from $\mathbb{R}$ to the circle.
The addition formulae for elliptic functions come from the fact that elliptic curves form a group.

My goal here is to find some transcendental functions that have nice addition formulae that come from considering the group $E(2)$ of Euclidean motions in two dimensions consisting of translations, rotations and reflections.

\section{The Euclidean group $E(2)$}
The elements of $E(2)$ are generated by the translations
\[
T_{(a,b)}(x,y) = (x+a,y+b),
\]
rotations
\[
R_{\phi}(x,y) = (x\cos\phi-y\sin\phi,x\sin\phi+y\cos\phi)
\]
and reflections
\[
C(x,y) = C(x,-y)
\]

\section{A representation of $E(2)$}
We can define a representation of $E(2)$ on the complex-valued continuous functions on the plane, $C(\mathbb{R},\mathbb{C})$,
by the rule that takes an element $g$ of $E(2)$ to $f \circ g$.
So, for example, $(Cf)(x,y) = f(x,-y)$ and $(T_{(a,b)}f)(x,y) = f(x+a,y+b)$.

I'm going to use various coordinate systems to describe points in the plane.
For example, if we define $r$ and $\theta$ by
\begin{align*}
x & = r\cos(\theta) \\
y & = r\sin(\theta) 
\end{align*}
then we can think of a function $f$ on the plane as a function of $x$ and $y$ or as a function of $r$ and $\theta$.
I'm going to use the same symbol $f$ for both of these functions even though technically these are different functions.
So $f(x,y) = f(r,\theta)$.

Now consider functions of the form
\begin{equation}
f_n(r,\theta)=b_n(r)e^{in\theta}. \label{rot}
\end{equation}
These have a particularly nice behaviour when acted on my rotations.
In fact
\[
(R_\phi f_n)(x,y) = f(x,y)e^{in\phi}.
\]
Rotations are turned into multiplications.
It'd be nice if we could also turn translations into multiplications (as the Fourier transform does) but this is impossible because $E(2)$ is not a commutative group and rotations don't commute with translations.
We'll do the next best thing, pick functions $b_m$ that behave nicely under translation.

We can make our life easier by first considering infinitesimal translations.
Conceptually, the derivative of a function is the amount it changes under infinitesimal translations.
If a function behaves nicely under translations you can expect it to have a derivative that's easy to compute.
So let's pick $b_n$ so that the $f_n$ take a particularly simple form when differentiated.
For convenience define $z=x+iy$ so we can also think of functions $f$ on the plane as functions of $z$.

Differentiating and simplifying Equation~(\ref{rot}) we get both
\begin{align}
\frac{\partial f_n}{\partial x} &= 
    \frac{e^{in\theta}}{r}\Big(-\frac{inyb_n(r)}{r}+xb_n'(r)\Big) \label{partialx}\\
\frac{\partial f_n}{\partial y} &= 
    \frac{e^{in\theta}}{r}\Big(\frac{inxb_n(r)}{r}+yb_n'(r)\Big) \label{partialy}
\end{align}
This is a little messy.
But there's a trick to simplify.
We have $x$ and $y$ appearing in different places in both of the right hand sides, but by forming $\partial f_n/\partial x+i\partial f_n/\partial y$ they both become multiples of $z$ which can be factored out.
We could do the same using $-i$ instead.
Defining the derivatives with respect to $z$ and its complex conjugate $\bar{z}$ by
\begin{align*}
\frac{\partial}{\partial z} &= \frac{1}{2}\Big(\frac{\partial}{\partial x}-i\frac{\partial}{\partial y}\Big)\\
\frac{\partial}{\partial\bar{z}} &= \frac{1}{2}\Big(\frac{\partial}{\partial x}+i\frac{\partial}{\partial y}\Big)\\
\end{align*}
we get both
\begin{align*}
2\frac{\partial f_n}{\partial\bar{z}} & = e^{i(n+1)\theta}
    \Big(-\frac{nb_n(r)}{r}+b_n'(r)\Big)\\
2\frac{\partial f_n}{\partial z} & = e^{i(n-1)\theta}
    \Big(\frac{nb_n(r)}{r}+b_n'(r)\Big)
\end{align*}
(Recall that $\partial f/\partial\bar{z}=0$ is the condition for $f$ to be analytic and $\partial f/\partial z$ is the usual analytic derivative though we don't use that here.)

We're interested in functions of the form
$f_n(r,\theta)=b_n(r)e^{in\theta}$
and these become particularly nice if we choose
\begin{align*}
b_{n+1}(r) & = \frac{nb_n(r)}{r}-b_n'(r) \\
b_{n-1}(r) & = \frac{nb_n(r)}{r}+b_n'(r)
\end{align*}
or equivalently
\begin{align}
\frac{2nb_n(r)}{r} & =  b_{n-1}(r)+b_{n+1}(r) \label{sum} \\
2b_n'(r) & =  b_{n-1}(r)-b_{n+1}(r) \label{deriv}
\end{align}
(See AS-9.1.27. Note that I use the notation AS-aa.bb.cc to refer to formulae in Abramowitz and Stegun.)
Any family of functions $(b_n)$ satisfying these properties will result in the nice relations:
\begin{align*}
2\frac{\partial f_n}{\partial\bar{z}} & = -f_{n+1} \\
2\frac{\partial f_n}{\partial z} & = f_{n-1}.
\end{align*}
which are equivalent to
\begin{align}
2\frac{\partial f_n}{\partial x} & = f_{n-1}-f_{n+1} \label{sum3} \\
-2i\frac{\partial f_n}{\partial y} & = f_{n+1}+f_{n-1} \label{sum4}.
\end{align}

\section{Exponentiating up to translation}
Let's collect together the $(b_n)$ in a single generating function
\[
G(r,t) = \sum_{k=-\infty}^\infty b_k(r)t^k
\]
We get
\begin{align*}
\frac{\partial G(r,t)}{\partial r} &= \sum_{k=-\infty}^\infty \frac{1}{2}(b_{k-1}(r)-b_{k+1}(r))t^k\\
&= \sum_{k=-\infty}^\infty \frac{1}{2}(t-t^{-1})b_k(r)t^k \\
&= \frac{1}{2}(t-t^{-1})G(r,t)
\end{align*}
So we have
\[
G(r,t) = e^{\frac{1}{2}r(t-t^{-1})}g(t)
\]
for some $g$ determined by boundary conditions.
For simplicity we can pick $g(t) = 1$ and define $J_k(r)$ by
\begin{equation}
\boxed{\sum_{k=-\infty}^\infty J_k(r)t^k = G(r,t) = e^{\frac{1}{2}r(t-t^{-1})}}\label{defn}
\end{equation}
We can determine each of the $J_k(r)$ by expanding the Taylor series for $G(r, t)$.
The $J_k(r)$ are known as the Bessel functions of the first kind and Equation~(\ref{defn}) is often taken as their definition.
I hope it can be seen that the form of Equation~(\ref{defn}) comes directly from Equation~(\ref{sum3}) which in turn comes directly from our goal of making the derivatives of the $(b_n)$ as simple as possible without becoming trivial.

Note that
\begin{align*}
\sum_{k=-\infty}^\infty (-1)^kJ_{-k}(r)t^k
&= \sum_{k=-\infty}^\infty J_{-k}(r)(-t)^k \\
&= \sum_{k=-\infty}^\infty J_k(r)(-t^{-1})^k \\
&= G(r,-t^{-1}) \\
&= G(r,t)
\end{align*}
meaning that $J_{-k}(r) = (-1)^kJ_{k}(r)$.

\section{An addition law}
Because of the addition law for exponentials we have
\[
G(r+s,t) = G(r,t)G(s,t).
\]
We get
\begin{align*}
G(r+s,t) &= \sum_{k=-\infty}^\infty J_k(r)t^k\sum_{l=-\infty}^\infty J_l(r)t^l\\
&= \sum_{k=-\infty}^\infty \Big(\sum_{m=-\infty}^\infty J_{m}(r)J_{k-m}(s) \Big) t^k
\end{align*}
and so
\[
J_k(r+s) = \sum_{m=-\infty}^\infty J_{m}(r)J_{k-m}(s)
\]
This is the well known addition law for Bessel functions, AS-9.1.75.
We appear to have succeeded in our quest!

But this is not the addition law we were looking for.
Our goal was to find addition laws corresponding to multiplication in the group $E(2)$.
But this addition law is a 1-dimensional addition law.
We need to go back to Equation~(\ref{rot}) and consider functions in the plane.
So define
\[
\boxed{B_n(r,\theta) = J_n(r)e^{in\theta}}.
\]
Because of Equation~(\ref{deriv}) we expect these to have nice behaviour under translation.
In fact, define
\begin{align*}
H(r,\theta,t) &= \sum_{k=-\infty}^\infty B_k(r,\theta)t^k \\
&= \sum_{k=-\infty}^\infty J_k(r)(te^{i\theta})^k \\
&= G(r,te^{i\theta}) \\
&= \exp\frac{1}{2}r(te^{i\theta}-t^{-1}e^{-i\theta}) \\
&= \exp\frac{1}{2}(tz-t^{-1}\bar{z}) \\
&= \exp\frac{1}{2}(x(t-t^{-1})+iy(t+t^{-1}))
\end{align*}
So if we have 2D vectors $\myvec{p}$ and $\myvec{q}$, then
\[
H(\myvec{p}+\myvec{q},t) = H(\myvec{p},t)H(\myvec{q},t)
\]
This tells us that
\begin{equation}
\boxed{B_n(\myvec{p}+\myvec{q}) = \sum_{k=-\infty}^\infty B_k(\myvec{p})B_{n-k}(\myvec{q})}\label{addition}
\end{equation}
\textit{This} is the addition law we're after.
It expresses the group law in $E(2)$ that $T_{\myvec{p}+\myvec{q}}=T_{\myvec{p}}T_{\myvec{q}}$.

Using Figure~\ref{triangle} we can write (\ref{addition}) this in a more traditional, but also more obfuscated fashion.
Using the notation $\angle\myvec{p}$ to mean the angle between the vector $\myvec{p}$ and the $x$-axis:
\[
J_k(|\myvec{p}+\myvec{q}|)e^{ik\angle(\myvec{p}+\myvec{q})} = \sum_{m=-\infty}^\infty J_m(|\myvec{p}|)J_{k-m}(|\myvec{q}|)e^{im\angle\myvec{p}}e^{i(k-m)\angle\myvec{q}}
\]

\tikzset{->-/.style={decoration={
    markings,
    mark=at position #1 with {\arrow{>}}},postaction={decorate}}}

\begin{figure}
\centering
\begin{tikzpicture}[>=stealth]
\draw[->-=0.5] (0,0) node[left]{$0$}
%node[shift={(0.5,0.05)}]{$\theta$}
-- (4,-2) node[midway,below left]{$\myvec{p}$};
\draw[->-=0.5] (4,-2) node[shift={(-0.15,0.4)}]{$\phi$} -- (5,3) node[midway,right] {$\myvec{q}$};
\draw[->-=0.5] (0,0) -- (5,3) node[midway,above left] {$\myvec{p}+\myvec{q}$} node[shift={(-0.3,-0.4)}]{$\psi$};
\end{tikzpicture}
\caption{A triangle of vectors}
\label{triangle}
\end{figure}

We have
\begin{align*}
%\angle\myvec{p}+\theta & = \angle(\myvec{p}+\myvec{q}) \\
\angle\myvec{p}+\pi-\phi & = \angle(\myvec{q}) \\
\angle(\myvec{p}+\myvec{q})+\psi & = \angle(\myvec{q}) 
\end{align*}

Therefore
\[
J_k(|\myvec{p}+\myvec{q}|)e^{ik(\angle(\myvec{p}+\myvec{q})-\angle\myvec{q})} = \sum_{m=-\infty}^\infty J_m(|\myvec{p}|)J_{k-m}(|\myvec{q}|)e^{im(\angle\myvec{p}-\angle\myvec{q})}
\]
so
\begin{align*}
J_k(|\myvec{p}+\myvec{q}|)e^{ik\psi} & = \sum_{m=-\infty}^\infty J_m(|\myvec{p}|)J_{k-m}(|\myvec{q}|)e^{im(\phi-\pi)} \\
                                 & = \sum_{m=-\infty}^\infty J_m(|\myvec{p}|)J_{k-m}(|\myvec{q}|)(-1)^me^{im\phi}
\end{align*}

This is essentially Graf's addition theorem AS-9.1.79.

\section{A representation of $E(2)$}
We can now state a representation of $E(2)$.
Our carrier space is the space of ``Laurent'' series $\sum_{k=-\infty}^\infty a_kt^k$.
The representation $r$ is given by:
\begin{align*}
r(R_\phi) & : p(t) \rightarrow p(e^{i\phi}t)\\
r(T_{x,y}) & : p(t) \rightarrow e^{\frac{1}{2}(x(t-t^{-1})+iy(t+t^{-1}))}p(t) \\
r(C) & : p(t) \rightarrow p(-t^{-1})
\end{align*}

So in summary, we sought a basis of functions that is well behaved under rotation, translation and reflection.
We were ultimately led to the representation of $E(2)$ above.
And all of the properties of Bessel functions of the first kind (for integer modulus) follow from the fact the group representation, in particular the additions laws.

\section{Acknowledgements}
I learnt about the relationship between Bessel functions and $E(2)$ from \textit{An Overview of the Relationship between Group Theory and Representation Theory to the Special Functions in Mathematical Physics} by Wasson and Gilmore.
I tried to give a self-contained elementary account of what they described.
Everyone traces the theory back to \textit{Special Functions and the Theory of Group Representations} by Vilenkin.

\end{document}
