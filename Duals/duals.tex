\documentclass[12pt,reqno]{article}      % Sets 12pt font, equation numbers on right
\usepackage{amsmath,amssymb,amsfonts,amsthm} % Typical maths resource packages
\usepackage{graphics}                 % Packages to allow inclusion of graphics
\usepackage{color}                    % For creating coloured text and background
\usepackage{optidef}
\usepackage{bm}
\usepackage{tikz}
\usepackage{mdframed}
\usetikzlibrary{decorations.markings}

\usepackage[colorlinks,citecolor=blue,linkcolor=blue]{hyperref}

\theoremstyle{definition}
%\newtheorem{example}{Example}
\newcommand{\dom}{\mathop{\textrm{dom}}}

\newcounter{example}
\newenvironment{example}[1][]
{\refstepcounter{example}\par\medskip
    \noindent \textbf{\theexample. #1}
\rmfamily}{\medskip}

\newcommand{\bmw}{\bm{w}}
\newcommand{\bmx}{\bm{x}}
\newcommand{\bmy}{\bm{y}}
\newcommand{\bma}{\bm{a}}
\newcommand{\bmb}{\bm{b}}
\newcommand{\bmc}{\bm{c}}
\newcommand{\bmA}{\bm{A}}
\newcommand{\bmlambda}{\bm{\lambda}}
\newcommand{\bmmu}{\bm{\mu}}
\newcommand{\bmnu}{\bm{\nu}}
\newcommand{\bbR}{\mathbb{R}}

\newcommand{\problem}{\noindent\textbf{Problem~\theexample.}}
\newcommand{\dual}{\noindent\textbf{Dual~\theexample.}}
\newtheorem{theorem}{Theorem}

\title{100 Optimization Problems and their Duals}

\begin{document}
\maketitle

\section{One problem to rule them all}

\begin{example}[The definition of the dual.]
This is the grandaddy of them all.
Every subsequent example is a special case of this one.
The primal problem:
\begin{mdframed}
\problem
\begin{mini}{x \in \cal{D}}{f(x)}{}{}
\addConstraint{g_i(x)}{\le 0,}{i=1,\ldots m}
\addConstraint{h_i(x)}{= 0,\quad}{i=1,\ldots n}
\end{mini}
\end{mdframed}
We define the Lagrangian function by:
\[
L(x,\lambda,\mu) = f(x)+\sum_{i=1}^m\lambda_ig_i(x)+\sum_{i=1}^n\nu_ih_i(x)
\]
The dual function is now defined by
\[
g(\lambda,\nu) = \mathop{\inf}_{x\in\cal{d}}L(x,\lambda,\nu)
\]
The $g(\lambda,\nu)$ are all lower bounds for the minimum of the primal problem.

Define the dual problem as:

\begin{mdframed}[nobreak]
\dual
\begin{maxi}{\lambda,\nu}{g(\lambda,\nu)}{}{}
\addConstraint{\lambda}{\ge0}
\end{maxi}
\end{mdframed}

The solution to the dual problem clearly bounds the solution to the primal problem from below.

Often there are values of $\lambda$ and $\nu$ for which $g(\lambda,\nu)=-\infty$ making $g(\lambda,\nu)$ vacuously a lower bound for the primal problem.
Define $\dom g$ as the set of $(\lambda,\nu)$ where $g(\lambda,\nu) > -\infty$.
Then the following is essentially the same same as the dual problem:
\begin{maxi}{\lambda,\nu}{g(\lambda,\nu)}{}{}
\addConstraint{\lambda}{\ge0}
\addConstraint{(\lambda,\nu)}{\in\dom g}
\end{maxi}
We will usually use the latter formulation.
\end{example}

Sometimes we'll consider maximisations and sometimes minimisations.
It can be easy to get confused about signs.
Suppose we're optimising $f(x)$ subject to a constraint $g(x) \ge 0$, $g(x)\le 0$ or $g(x)=0$.
Then think of the term
$\lambda g(x)$ as a penalty for violating the constraint.
If we're minimising then it's a penalty if it's positive and if we're maximising then
it's a penalty if it's negative.

For the constraint $g(x)=0$, the constraint is violated both when $g(x)>0$ and when $g(x)<0$.
We must allow $\lambda$ to be both positive and negative.

For the constraint $g(x)\le0$ in a maximisation problem, say,
the constraint is violated when $g(x)>0$.
For maximisations, penalties are negative, so for $\lambda g(x)$ to be negative,
we require the constraint on $\lambda$ to be $\lambda\le0$.
Our Lagrangian is $f(x)+\lambda g(x)$ subject to $\lambda\le0$.

\section{The problems}
We'll start with some problems that are simple enough that you might think of them as degenerate, but which still have non-trivial content.

\begin{example}[A single equality constraint.]
\begin{mdframed}
\problem
\begin{mini}{x \in \mathbb{R}}{f(x)}{}{}
\addConstraint{x=a}
\end{mini}
\end{mdframed}
Clearly the solution is $f(a)$ achieved at $x=a$.

Define
\[
L(x,\nu) = f(x)+\lambda(a-x)
\]

We now have
\begin{align}
g(\lambda) & = \mathop{\inf}_{x}L(x,\lambda) \\
           & = \lambda a+\mathop{\inf}_{x}(f(x)-\lambda x) \\
\end{align}

The dual problem is
\begin{mdframed}
\dual
\begin{maxi}{\lambda \in \mathbb{R}}{g(\lambda)}{}{}
\end{maxi}
\end{mdframed}

\subsection{Geometric interpretation}
Start with a line of the form $y = \lambda x+b$.
For a fixed $\lambda$, adjusting $b$ slides this line up and down the $y$-axis.
Consider the problem of sliding the line up so that it just touches the curve $y=f(x)$ from below.
We want to find $b$ such that the smallest gap between $y=f(x)$ and $y=\lambda x+b$ is zero.
If $b$ is the size of the smallest (signed) gap between $f(x)$ and $\lambda x$ then the line $y=\lambda x+b$ will be the translate of the line that just touches $y=f(x)$.
For any given $\lambda$, the line $y=\lambda(x-a)x+g(\lambda)$ is the line of gradient $\lambda$ that just touches $y=f(x)$.
Clearly $f(a) > \lambda(a-a)+g(\lambda) = g(\lambda)$.

Now consider the problem of finding $\lambda$ such the that the line just touches $y=f(x)$ from below at $x=a$.
This is clearly given by maximizing $g(]lambda)$.
So the dual problem finds gradient of a line just touching $y=f(x)$ from below.

Consider the case where $f(x)$ is differentiable.
Then the maximum in the dual problem occurs when $g'(\lambda) = 0$.
So we have $\lambda = f'(a)$.
In other words, the line with tangent $f'(a)$ just touches $f(x)$ from below at $x=a$.

\subsection{Physical interpretation}
Consider $f$ to be a potential field.
This gives rise to a force $-f'(x)$.
Suppose a particle is in the potential field.
What do we need to do to ensure the particle is constrained to $x=a$?
We need to supply a force $f'(a)$ that cancels out the force $-f'(x)$ due to the potential.
We can view this another way.
A fixed force $\lambda$ can be seen as the force arising from the potential $\lambda(a-x)$.
So to keep the particle static at $x=a$ we need to add a potential $\lambda(a-x)$ for some $\lambda$.
The particle is at rest at the minimum of the potential.
$g(Î»)$ is the potential at $x=a$ when new potential is added.
Clearly it equals the minimum potential of a particle with a potential $f$ constrained to $a$.
This is generally true: we can can often think of the Lagrange multipliers as being the forces requireed to enforce a constraint.
\end{example}

\section{Fenchel dual}

\section{Linear programming}

\begin{example}[A linear program.]
\begin{mdframed}
\problem
\begin{maxi}{\bmx\in\mathbb{R}^n}{\bmc\cdot \bmx}{}{}
\addConstraint{\bmA\bmx}{\le \bmb}
\addConstraint{\bmx}{\ge 0}
\end{maxi}
\end{mdframed}

The Lagrangian is given by
\begin{align}
L(\bmx,\bmlambda,\bmmu) &= \bmc\cdot\bmx+\bmlambda\cdot(\bmA\bmx-\bmb)+\bmmu\cdot x \\
                        &= (\bmc+\bmA^T\bmlambda+\bmmu)\cdot x-\bmb\cdot\bmlambda 
\end{align}
The maximum is trivially $\infty$ unless $\bmc+\bmA^T\bmlambda+\bmmu = 0$.
So we have
\[
g(\bmlambda,\bmmu) = -\bmb\cdot\bmlambda
\]
with $\dom g = \{(\lambda,\mu) \mid \bmc+\bmA^T\bmlambda+\bmmu = 0, \bmlambda \le 0, \bmmu \ge 0\}$.

So the dual problem is

\begin{mini}{\bmlambda,\bmmu\in\mathbb{R}^m}{-\bmb\cdot\bmlambda}{}{}
\addConstraint{\bmc+\bmA^T\bmlambda+\bmmu}{=0}
\addConstraint{\bmlambda}{\le0}
\addConstraint{\bmmu}{\ge0}
\end{mini}

In the presence of the condition $\bmmu\ge0$,  condition $\bmc+\bmA^T+\bmmu=0$ is equivalant to $\bmc+\bmlambda^T\bmA\le0$.
Define the new variable $\bmy=-\bmlambda$.
The dual problem is now
\begin{mdframed}
\dual
\begin{mini}{\bmy\in\mathbb{R}^m}{\bmb\cdot\bmy}{}{}
\addConstraint{\bmA^T\bmy}{\ge\bmc}
\addConstraint{\bmy}{\ge0}
\end{mini}
\end{mdframed}

\begin{theorem}
(Strong Duality) There are four possibilities:
\begin{enumerate}
\item Both primal and dual have no feasible solutions (are infeasible).
\item The primal is infeasible and the dual unbounded.
\item The dual is infeasible and the primal unbounded.
\item Both primal and dual have feasible solutions and their values are equal.
\end{enumerate}
\end{theorem}
\end{example}

\begin{example}[Point in convex hull]

\begin{figure}[h]
\begin{center}
\begin{tikzpicture}
    \fill[black] (0,0) circle (.4ex);
    \fill[black] (2,0) circle (.4ex);
    \fill[black] (4,2) circle (.4ex);
    \fill[black] (1,3) circle (.4ex);
    \fill[black] (2,2) circle (.4ex);
    \draw[thick] (0,0) -- (2,0) -- (4,2) -- (1,3) -- (0,0);
    \draw (0,0) node[below] {$\bmx_1$};
    \draw (2,0) node[below] {$\bmx_2$};
    \draw (4,2) node[right] {$\bmx_3$};
    \draw (1,3) node[above] {$\bmx_4$};
    \draw (2,2) node[below] {$\bmy$};
\end{tikzpicture}
\end{center}
\end{figure}

\begin{mdframed}
\problem
\begin{mini}{\alpha_i}{0}{}{}
\addConstraint{\sum_i\alpha_i\bmx_i}{=\bmy}
\addConstraint{\sum_i\alpha_i}{=1}
\addConstraint{\alpha_i}{\ge 0}
\end{mini}
\end{mdframed}
We form the Lagrangian
\[
L(\alpha, \bmlambda, \mu, \nu_i) = \bmlambda\cdot(\sum_i\alpha_i\bmx_i-\bmy)+\mu(\sum_i\alpha_i-1)-\sum_i\nu_i\alpha_i
\]
where $\nu_i\ge0$.
\[
L(\alpha_i, \bmlambda, \mu, \nu_i) = \sum_i(\bmlambda\cdot\bmx_i+\mu-\nu_i)\alpha_i-\bmlambda\cdot y-\mu
\]
Define
\begin{align}
g(\bmlambda, \mu, \nu_i) & = \mathop{\textrm{min}}_{\alpha_i}L(\alpha_i,\bmlambda,\mu,\nu_i)\\
& = -\bmlambda\cdot y-\mu
\end{align}
where $\bmlambda\cdot\bmx_i+\mu-\nu_i=0$ and $\nu_i\ge0$

\begin{mdframed}
\dual
\begin{maxi}{\bmlambda,\mu}{-\bmlambda\cdot \bmy-\mu}{}{}
\addConstraint{\bmlambda\cdot \bmx_i+\mu}{\ge 0}
\end{maxi}
\end{mdframed}
\end{example}

When $\bmlambda\ne0$, the equation $\bmlambda\cdot\bmx+\mu=0$ is the equation of a hyperplane in $\mathbb{R}^n$.
Weak duality tells us that the dual objective is always less than or equal to the primal objective and hence that $\bmlambda\cdot \bmy+\mu$ is always greater than or equal to zero. In other words, if all of the $\bmx_i$ lie in the region $\{\bmx|\bmlambda\cdot \bmx+\mu\ge0\}$ then so does any $\bmy$ feasible in the primal problem.

There is a converse to this. Suppose the primal problem is infeasible.
The dual is still feasible because there is some hyperplane with all of the $\bmx_i$ on one side of it.
By the strong duality theorem the dual problem must be unbounded.
This means we can choose $\bmlambda$ and $\mu$ so that $\bmlambda\cdot\bmx_i+\mu\ge0$ for all $i$ but with $\bmlambda\cdot\bmy+\mu\le0$. In other words we have a hyperplane that separates the $\bmx_i$ from $\bmy$.

\begin{figure}[h]
\begin{center}
\begin{tikzpicture}
    \fill[black] (0,0) circle (.4ex);
    \fill[black] (2,0) circle (.4ex);
    \fill[black] (4,2) circle (.4ex);
    \fill[black] (1,3) circle (.4ex);
    \fill[black] (4,0) circle (.4ex);
    \draw[thick] (0,0) -- (2,0) -- (4,2) -- (1,3) -- (0,0);
    \draw (0,0) node[below] {$\bmx_1$};
    \draw (2,0) node[below] {$\bmx_2$};
    \draw (4,2) node[right] {$\bmx_3$};
    \draw (1,3) node[above] {$\bmx_4$};
    \draw (4,0) node[below] {$\bmy$};
    \draw[thick] (1,-2) -- (6,3);
    \draw (5,2) node[below right] {$\bmlambda\cdot\bmx+\mu=0$};
\end{tikzpicture}
\end{center}
\end{figure}

\begin{example}[Relaxed set cover.]
Consider the following problem: we have a set $U$ and a collection of subsets $S_i$ indexed by elements $i\in \{1,\ldots,n\}$.
We'd like to find the smallest number of $S_i$ that cover $U$, i.e. find the smallest subset of indices, $J$, such that $\bigcup_{i\in J}S_i = U$.
Let $x_i$ be indicator variables so that $x_i=1$ if $i\in J$ and $x_i=0$ otherwise.
We can express our problem as the following optimisation:
\begin{mini}{x_i}{\sum_{i=1}^nx_i}{}{}
\addConstraint{\sum_{i:v\in S_i}x_i}{\ge 1\quad}{\forall v\in U}
\addConstraint{x_i}{\in \{0,1\}\quad}{\forall i\in\{1,\ldots,n\}}
\end{mini}
The first constraint tells us that every point in $u$ must appear in at least one of the chosen subsets.
This is a non-convex problem because the set $\{0,1\}$ is not convex.
We can relax this problem to allow the $x_i$ to lie in $[0,1]$.
Solutions to this problem will provide an upper bound to the original problem.
\begin{mdframed}
\problem
\begin{mini}{x_i}{\sum_{i=1}^nx_i}{}{}
\addConstraint{\sum_{i:v\in S_i}x_i}{\ge 1\quad}{\forall v\in U}
\addConstraint{x_i}{\le 1\quad}{\forall i\in\{1,\ldots,n\}}
\addConstraint{x_i}{\ge 0\quad}{\forall i\in\{1,\ldots,n\}}
\end{mini}
\end{mdframed}
\end{example}

\begin{example}[Relaxed knapsack]
\end{example}

\begin{example}[Optimal Transport]
We have a set of locations $I$ and another set of locations $J$.
At each location $i$ in $I$ we have an amount $v_i$ of some good.
We want to transport the goods so that we end up with amount $v_j$ at each location $j$ in $J$.
The total amount of good is conserved so we have $\sum_iv_i=\sum_jw_j$.
The cost of transporting one unit from $i$ to $j$ is $c_{ij}$.
We wish to minimise the total cost of transport.

Suppose we transport amount $t_{ij}$ from $i$ to $j$.
The total amount transported from $i$ must be $v_i$ so we have $\sum_jt_{ij}=v_i$.
Similarly an amount $w_j$ ends up at $j$ so we have $\sum_it_{ij}=w_j$.
\begin{mdframed}
\problem
\begin{mini}{(t_{ij})}{\sum_{i,j}c_{ij}t_{ij}}{}{}
\addConstraint{\sum_jt_{ij}}{=v_i}
\addConstraint{\sum_it_{ij}}{=w_j}
\addConstraint{t_{ij}}{\ge0}
\end{mini}
\end{mdframed}
We have
\begin{align*}
L(t_{ij},\lambda_i,\mu_j,\nu_{ij}) &= \sum_{ij}c_{ij}t_{ij}+\sum\lambda_i(\sum_jt_{ij}-\nu_i)-\sum_j\mu_j(\sum_it_{ij}-w_j)-\sum_{i,j}\nu_{ij}t_{ij} \\
&= \sum_{ij}t_{ij}(c_{ij}+\lambda_i-\mu_j-\nu_{ij})-\sum_i\lambda_iv_i+\sum_j\mu_jw_j
\end{align*}
\begin{mdframed}
\begin{maxi}{\lambda_i,\mu_j}{-\sum_i\lambda_iv_i+\sum_j\mu_jw_j}{}{}
\addConstraint{-\lambda_i+\mu_j}{\le c_{ij}}
\end{maxi}
\end{mdframed}
\subsection{Economics interpretation}
A company is going to provide transportation of the goods from the $I$ to the $J$.
They charge $\lambda_i$ per unit for pickup at each $i$ and $\mu_j$ for delivery per unit at each $j$.
It costs anyone $c_{ij}$ per unit to move goods from $i$ to $j$.
Their goal is to maximise profits.
Note that they must charge so that $-\lambda_i+\mu_j\le c_{ij}$ otherwise the customer could just move the goods from $i$ to $j$ themselves.
\end{example}

\begin{example}[Two player zero-sum games.]
We have two players, A and B.
Simultaneously, player $A$ picks an $i$ in the set $I$ and $B$ picks a $j$ in the set $J$.
The outcome is that $A$ must pay $B$ \$$P_{ij}$.

B would like to maximise the payment from A to B and B would like to minimise it.
B must adopt a strategy that maximises the outcome on the assumption that A is trying to thwart them.
B can also adopt a mixed strategy, picking option $j$ with probability $x_j$.
This can be written as the optimisation
\begin{maxi}{x_j}{\min_i\sum_jP_{ij}x_j}{}{}
\addConstraint{x_j}{\ge0\quad}{\forall j\in J}
\addConstraint{\sum_j x_j}{=1\quad}{}
\end{maxi}
\begin{mdframed}
\problem
\begin{maxi}{x_j,z}{z}{}{}
\addConstraint{z}{\le \sum_j P_{ij}x_j\quad}{\forall i\in I}
\addConstraint{x_j}{\ge0\quad}{\forall j\in J}
\addConstraint{\sum_j x_j}{=1\quad}{}
\end{maxi}
\end{mdframed}

\end{example}

\begin{example}[Support Vector Machines]
We are given a set of points $\{\bmx_i\}$ in $\bbR^n$.
For each $i$ we are also given a $y_i\in\{-1,1\}$.
In Figure~\ref{svm1} the red points are the $\bmx_i$ for which $y_i=-1$ and the blue points are the $\bmx_i$ such that $y_i=1$.
The goal is to find a vector $\bmw_i\in\bbR^n$ and $b\in\bbR$ that separate the red and blue points in the sense that $\bmw\cdot\bmx+b<0$ when $y_i=-1$ and $\bmw\cdot\bmx+b>0$ when $y_i=1$.
For example, the $\bmx_i$ might be the reflectivities of a material at various wavelengths with $y_i$ indicating whether it is material $A$ or material $B$.
If we collect reflectivities for a new sample of material we can use $\bmw\cdot\bmc+b$ to predict whether the sample is of material $A$ or $B$.
\begin{figure}[h]
\begin{center}
\begin{tikzpicture}
    \fill[red] (2,2) circle (.4ex);
    \fill[red] (3.4,3.2) circle (.4ex);
    \fill[red] (4,2.4) circle (.4ex);
    \fill[red] (2.6,5.4) circle (.4ex);
    \fill[red] (3.2,4.8) circle (.4ex);
    \fill[red] (3.4,3.2) circle (.4ex);
    \fill[red] (4.2,4.8) circle (.4ex);
    \fill[red] (4.6,4.6) circle (.4ex);
    \fill[red] (4.5,6.0) circle (.4ex);
    \fill[red] (5,4) circle (.4ex);
    \fill[blue] (7.0,6.3) circle (.4ex);
    \fill[blue] (7.8,4.4) circle (.4ex);
    \fill[blue] (7.8,5.2) circle (.4ex);
    \fill[blue] (7.0,4.0) circle (.4ex);
    \fill[blue] (7.8,6.8) circle (.4ex);
    \fill[blue] (9.0,3.4) circle (.4ex);
    \fill[blue] (9.2,2.8) circle (.4ex);
    \fill[blue] (9.6,5.8) circle (.4ex);
    \draw[thick,gray] (6,0) -- (4,8);
    \draw[thick] (7,0) -- (5,8);
    \draw[thick,gray] (8,0) -- (6,8);

    \draw (6,0) node[above left] {$\bmw\cdot\bmx+b=-1$};
    \draw (8,0) node[above right] {$\bmw\cdot\bmx+b=+1$};
\end{tikzpicture}
\caption{Training data}
\label{svm1}
\end{center}
\end{figure}
There may be many suitable vectors $\bmw$.
It makes sense to choose the most economical one in the sense that $|\bmw|^2$ is minimised.
This has the effect of making the distance between the hypersurfaces $\bmw\cdot\bmx+b=-1$ and $\bmw\cdot\bmx+b=+1$ as large as possible, in effect ensuring the two classes are separated by as much distance as possible.
We can write the problem as
\begin{mdframed}
\problem
\begin{mini}{\bmw,b}{|\bmw|^2}{}{}
\addConstraint{y_i(\bmw\cdot\bmx_i+b)}{\ge 1}{\quad \forall i}
\end{mini}
\end{mdframed}
\end{example}

\begin{example}[SVM with soft margin]
\end{example}

\begin{example}[Max-flow min-cut]
\end{example}
\begin{example}[Two-player games]
\end{example}

\section{Quadratic programming}
\begin{example}[Linearly constrained closest point]
\begin{mdframed}
\problem
\begin{mini}{\bmx}{\frac{1}{2}|\bmx-\bmy|^2}{}{}
\addConstraint{\bmA\bmx}{= 0\quad}{}
\end{mini}
\end{mdframed}
Define
\[
L(\bmx,\bmy) = \frac{1}{2}|\bmx-\bmy|^2+\bmlambda^T\bmA\bmx
\]
so
\[
\nabla_{\bmx} L = \bmx-\bmy+\bmA^T\bmlambda
\]
At the minimum with respect to $\bmx$ we have
\[
\bmx = \bmy-\bmA^T\bmlambda
\]
Therefore $g(\bmlambda) = \min_{\bmx}L(\bmx,\bmlambda)$ is given by
\begin{align}
g(\bmlambda) &= \frac{1}{2}|\bmA^T\bmlambda|^2+\bmlambda^T\bmA(\bmy-\bmA^T\bmlambda)\\
&= \bmy^T\bmA^T\bmlambda-\frac{1}{2}|\bmA^T\bmlambda|^2
\end{align}
\begin{mdframed}
\dual
\begin{maxi}{\bmlambda}{-\frac{1}{2}|\bmA^T\bmlambda|^2+\bmy^T\bmA^T\bmlambda}{}{}
\end{maxi}
\end{mdframed}
\end{example}

\begin{example}[Fluid dynamics]
Suppose we have a graph with vertices $V$ and edges $(i,j)\in E\subset V\times V$ with $i<j$.
Each edge has a flow $f_{ij}$ which is from $i$ to $j$ if $f_{ij}>0$ and from $j$ to $i$ if $f_{ij}<0$.
A flow is incompressible if the total flow in or out of each vertex is zero, in other words if for each $i\in V$
\[
\sum_{j:(i,j)\in E} f_{ij} - \sum_{k:(k,i)\in E}f_{ki} = 0
\]
Given a flow that is not incompressible we can seek the closest incompressibleflow $e_{ij}$ to $f_{ij}$ in the $L_2$ sense.
In other words
\begin{mdframed}
\problem
\begin{mini}{e_{ij}}{\sum_{(i,j)\in E}|f_{ij}-e_{ij}|^2}{}{}
\addConstraint{\sum_{j:(i,j)\in E} e_{ij} - \sum_{k:(k,i)\in E}e_{ki}}{= 0\quad}{\forall i\in V}
\end{mini}
\end{mdframed}
\begin{figure}[h]
\begin{center}
\begin{tikzpicture}
\begin{scope}[very thick,decoration={markings, mark=at position 0.5 with {\arrow{>}}}] 
    \fill[black] (0,0) circle (.4ex);
    \draw[thick,dashed] (0,0) -- (-1,0);
    \fill[black] (3,0) circle (.4ex);
    \draw[thick,dashed] (3,0) -- (4,1);
    \draw[thick,dashed] (3,0) -- (4,-1);
    \fill[black] (4,2) circle (.4ex);
    \draw[thick,dashed] (4,2) -- (5,1);
    \draw[thick,dashed] (4,2) -- (5,3);
    \fill[black] (1,3) circle (.4ex);
    \fill[black] (2,2) circle (.4ex);
    \draw[thick,postaction={decorate}] (0,0) -- (2,2) node[midway,below right] {$f_{01}$};    
    \draw[thick,postaction={decorate}] (2,2) -- (3,0) node[midway,below left] {$f_{12}$};    
    \draw[thick,postaction={decorate}] (2,2) -- (4,2) node[midway,below] {$f_{13}$};    
    \draw[thick,postaction={decorate}] (2,2) -- (1,3) node[midway,below left] {$f_{14}$};    
    \draw (0,0) node[below] {$0$};
    \draw (3,0) node[below left] {$2$};
    \draw (4,2) node[above left] {$3$};
    \draw (1,3) node[above] {$4$};
    \draw (2,2) node[above right] {$1$};
\end{scope}
\end{tikzpicture}
\end{center}
\caption{A graph with flows}
\end{figure}
Define
\[
L(e_{ij}, \lambda_i) = \sum_{(i,j)\in E}(e_{ij}-f_{ij})^2+\sum_i\lambda_i\big(\sum_{j:(i,j)\in E} e_{ij} - \sum_{k:(k,i)\in E}e_{ki}\big)
\]
To minimise with respect to the $e_{ij}$ consider
\[
\frac{\partial L}{\partial e_{mn}} = 2(e_{mn}-f_{mn})+\lambda_m-\lambda_n
\]
so
\[
e_{mn} = f_{mn}-\frac{1}{2}(\lambda_m-\lambda_n)
\]
\begin{mdframed}
\dual
\begin{maxi}{(\lambda_i)}{\sum_{(i,j)\in E}f_{ij}(\lambda_i-\lambda_j)-\frac{1}{2}(\lambda_i-\lambda_j)^2}{}{}
\end{maxi}
\end{mdframed}
\end{example}

\section{Non-linear examples}
\begin{example}[$L_q$ norm?]
\end{example}

\begin{example}[Maximum entropy probability distributions]
\end{example}

\end{document}
