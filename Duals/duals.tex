\documentclass[12pt,reqno]{article}      % Sets 12pt font, equation numbers on right
\usepackage{amsmath,amssymb,amsfonts,amsthm} % Typical maths resource packages
\usepackage{graphics}                 % Packages to allow inclusion of graphics
\usepackage{color}                    % For creating coloured text and background
\usepackage{optidef}
\usepackage{bm}
\usepackage{mdframed}

\usepackage[colorlinks,citecolor=blue,linkcolor=blue]{hyperref}

\theoremstyle{definition}
%\newtheorem{example}{Example}
\newcommand{\dom}{\mathop{\textrm{dom}}}

\newcounter{example}[section]
\newenvironment{example}[1][]
{\refstepcounter{example}\par\medskip
    \noindent \textbf{\theexample. #1}
\rmfamily}{\medskip}

\newcommand{\bmx}{\bm{x}}
\newcommand{\bmy}{\bm{y}}
\newcommand{\bma}{\bm{a}}
\newcommand{\bmb}{\bm{b}}
\newcommand{\bmc}{\bm{c}}
\newcommand{\bmA}{\bm{A}}
\newcommand{\bmlambda}{\bm{\lambda}}
\newcommand{\bmmu}{\bm{\mu}}
\newcommand{\bmnu}{\bm{\nu}}

\newcommand{\problem}{\noindent\textbf{Problem~\theexample.}}
\newcommand{\dual}{\noindent\textbf{Dual~\theexample.}}

\title{100 Optimization Problems and their Duals}

\begin{document}
\maketitle

\section{One problem to rule them all}

\begin{example}[The definition of the dual.]
This is the grandaddy of them all.
Every subsequent example is a special case of this one.
The primal problem:
\begin{mdframed}
\problem
\begin{mini}{x \in \cal{D}}{f(x)}{}{}
\addConstraint{g_i(x)}{\le 0,}{i=1,\ldots m}
\addConstraint{h_i(x)}{= 0,\quad}{i=1,\ldots n}
\end{mini}
\end{mdframed}
We define the Lagrangian function by:
\[
L(x,\lambda,\mu) = f(x)+\sum_{i=1}^m\lambda_ig_i(x)+\sum_{i=1}^n\nu_ih_i(x)
\]
The dual function is now defined by
\[
g(\lambda,\nu) = \mathop{\inf}_{x\in\cal{d}}L(x,\lambda,\nu)
\]
The $g(\lambda,\nu)$ are all lower bounds for the minimum of the primal problem.

Define the dual problem as:

\begin{mdframed}[nobreak]
\dual
\begin{maxi}{\lambda,\nu}{g(\lambda,\nu)}{}{}
\addConstraint{\lambda}{\ge0}
\end{maxi}
\end{mdframed}

The solution to the dual problem clearly bounds the solution to the primal problem from below.

Often there are values of $\lambda$ and $\nu$ for which $g(\lambda,\nu)=-\infty$ making $g(\lambda,\nu)$ vacuously a lower bound for the primal problem.
Define $\dom g$ as the set of $(\lambda,\nu)$ where $g(\lambda,\nu) > -\infty$.
Then the following is essentially the same same as the dual problem:
\begin{maxi}{\lambda,\nu}{g(\lambda,\nu)}{}{}
\addConstraint{\lambda}{\ge0}
\addConstraint{(\lambda,\nu)}{\in\dom g}
\end{maxi}
We will usually use the latter formulation.
\end{example}

\subsection{A mnemonic}
Sometimes we'll consider maximisations and sometimes minimisations.
It can be easy to get confused about signs.
Suppose we're optimising $f(x)$ subject to a constraint $g(x) \ge 0$, $g(x)\le 0$ or $g(x)=0$.
Then think of the term
$\lambda g(x)$ as a penalty for violating the constraint.
If we're minimising then it's a penalty if it's positive and if we're maximising then
it's a penalty if it's negative.

For the constraint $g(x)=0$, the constraint is violated both when $g(x)>0$ and when $g(x)<0$.
We must allow $\lambda$ to be both positive and negative.

For the constraint $g(x)\le0$ in a maximisation problem, say,
the constraint is violated when $g(x)>0$.
For maximisations, penalties are negative, so for $\lambda g(x)$ to be negative,
we require the constraint on $\lambda$ to be $\lambda\le0$.
Our Lagrangian is $f(x)+\lambda g(x)$ subject to $\lambda\le0$.

\section{The problems}
We'll start with some problems that are simple enough that you might think of them as degenerate, but which still have non-trivial content.

\begin{example}[A single equality constraint.]
\begin{mdframed}
\problem
\begin{mini}{x \in \mathbb{R}}{f(x)}{}{}
\addConstraint{x=a}
\end{mini}
\end{mdframed}
Clearly the solution is $f(a)$ achieved at $x=a$.

Define
\[
L(x,\nu) = f(x)+\lambda(a-x)
\]

We now have
\begin{align}
g(\lambda) & = \mathop{\inf}_{x}L(x,\lambda) \\
           & = \lambda a+\mathop{\inf}_{x}(f(x)-\lambda x) \\
\end{align}

The dual problem is
\begin{mdframed}
\dual
\begin{maxi}{\lambda \in \mathbb{R}}{g(\lambda)}{}{}
\end{maxi}
\end{mdframed}

\subsubsection{Geometric interpretation}
Start with a line of the form $y = \lambda x+b$.
For a fixed $\lambda$, adjusting $b$ slides this line up and down the $y$-axis.
Consider the problem of sliding the line up so that it just touches the curve $y=f(x)$ from below.
We want to find $b$ such that the smallest gap between $y=f(x)$ and $y=\lambda x+b$ is zero.
If $b$ is the size of the smallest (signed) gap between $f(x)$ and $\lambda x$ then the line $y=\lambda x+b$ will be the translate of the line that just touches $y=f(x)$.
For any given $\lambda$, the line $y=\lambda(x-a)x+g(\lambda)$ is the line of gradient $\lambda$ that just touches $y=f(x)$.
Clearly $f(a) > \lambda(a-a)+g(\lambda) = g(\lambda)$.

Now consider the problem of finding $\lambda$ such the that the line just touches $y=f(x)$ from below at $x=a$.
This is clearly given by maximizing $g(]lambda)$.
So the dual problem finds gradient of a line just touching $y=f(x)$ from below.

Consider the case where $f(x)$ is differentiable.
Then the maximum in the dual problem occurs when $g'(\lambda) = 0$.
So we have $\lambda = f'(a)$.
In other words, the line with tangent $f'(a)$ just touches $f(x)$ from below at $x=a$.

\subsubsection{Physical interpretation}
Consider $f$ to be a potential field.
This gives rise to a force $-f'(x)$.
Suppose a particle is in the potential field.
What do we need to do to ensure the particle is constrained to $x=a$?
We need to supply a force $f'(a)$ that cancels out the force $-f'(x)$ due to the potential.
We can view this another way.
A fixed force $\lambda$ can be seen as the force arising from the potential $\lambda(a-x)$.
So to keep the particle static at $x=a$ we need to add a potential $\lambda(a-x)$ for some $\lambda$.
The particle is at rest at the minimum of the potential.
$g(Î»)$ is the potential at $x=a$ when new potential is added.
Clearly it equals the minimum potential of a particle with a potential $f$ constrained to $a$.
This is generally true: we can can often think of the Lagrange multipliers as being the forces requireed to enforce a constraint.
\end{example}

\begin{example}[Linear programming.]
\begin{mdframed}
\problem
\begin{maxi}{\bmx\in\mathbb{R}^n}{\bmc\cdot \bmx}{}{}
\addConstraint{\bmA\bmx}{\le \bmb}
\addConstraint{\bmx}{\ge 0}
\end{maxi}
\end{mdframed}
\end{example}

The Lagrangian is given by
\begin{align}
L(\bmx,\bmlambda,\bmmu) &= \bmc\cdot\bmx+\bmlambda\cdot(\bmA\bmx-\bmb)+\bmmu\cdot x \\
                        &= (\bmc+\bmA^T\bmlambda+\bmmu)\cdot x-\bmb\cdot\bmlambda 
\end{align}
The maximum is trivially $\infty$ unless $\bmc+\bmA^T\bmlambda+\bmmu = 0$.
So we have
\[
g(\bmlambda,\bmmu) = -\bmb\cdot\bmlambda
\]
with $\dom g = \{(\lambda,\mu) \mid \bmc+\bmA^T\bmlambda+\bmmu = 0, \bmlambda \le 0, \bmmu \ge 0\}$.

So the dual problem is

\begin{mini}{\bmlambda,\bmmu\in\mathbb{R}^m}{-\bmb\cdot\bmlambda}{}{}
\addConstraint{\bmc+\bmA^T\bmlambda+\bmmu}{=0}
\addConstraint{\bmlambda}{\le0}
\addConstraint{\bmmu}{\ge0}
\end{mini}

In the presence of the condition $\bmmu\ge0$,  condition $\bmc+\bmA^T+\bmmu=0$ is equivalant to $\bmc+\bmlambda^T\bmA\le0$.
Define the new variable $\bmy=-\bmlambda$.
The dual problem is now
\begin{mdframed}
\dual
\begin{mini}{\bmy\in\mathbb{R}^m}{\bmb\cdot\bmy}{}{}
\addConstraint{\bmA^T\bmy}{\ge\bmc}
\addConstraint{\bmy}{\ge0}
\end{mini}
\end{mdframed}

\begin{example}[Relaxed set cover.]
Consider the following problem: we have a set $U$ and a collection of subsets $S_i$ indexed by elements $i\in \{1,\ldots,n\}$.
We'd like to find the smallest number of $S_i$ that cover $U$, i.e. find the smallest subset of indices, $J$, such that $\bigcup_{i\in J}S_i = U$.
Let $x_i$ be indicator variables so that $x_i=1$ if $i\in J$ and $x_i=0$ otherwise.
We can express our problem as the following optimisation:
\begin{mini}{x_i}{\sum_{i=1}^nx_i}{}{}
\addConstraint{\sum_{i:v\in S_i}x_i}{\ge 1\quad}{\forall v\in U}
\addConstraint{x_i}{\in \{0,1\}\quad}{\forall i\in\{1,\ldots,n\}}
\end{mini}
The first constraint tells us that every point in $u$ must appear in at least one of the chosen subsets.
This is a non-convex problem because the set $\{0,1\}$ is not convex.
We can relax this problem to allow the $x_i$ to lie in $[0,1]$.
Solutions to this problem will provide an upper bound to the original problem.
\begin{mdframed}
\problem
\begin{mini}{x_i}{\sum_{i=1}^nx_i}{}{}
\addConstraint{\sum_{i:v\in S_i}x_i}{\ge 1\quad}{\forall v\in U}
\addConstraint{x_i}{\le 1\quad}{\forall i\in\{1,\ldots,n\}}
\addConstraint{x_i}{\ge 0\quad}{\forall i\in\{1,\ldots,n\}}
\end{mini}
\end{mdframed}
\end{example}

\begin{example}[Two player zero-sum games.]
We have two players, A and B.
Simultaneously, player $A$ picks an $i$ in the set $I$ and $B$ picks a $j$ in the set $J$.
The outcome is that $A$ must pay $B$ \$$P_{ij}$.

B would like to maximise the payment from A to B and B would like to minimise it.
B must adopt a strategy that maximises the outcome on the assumption that A is trying to thwart them.
B can also adopt a mixed strategy, picking option $j$ with probability $x_j$.
This can be written as the optimisation
\begin{maxi}{x_j}{\min_i\sum_jP_{ij}x_j}{}{}
\addConstraint{x_j}{\ge0\quad}{\forall j\in J}
\addConstraint{\sum_j x_j}{=1\quad}{}
\end{maxi}
\begin{mdframed}
\problem
\begin{maxi}{x_j,z}{z}{}{}
\addConstraint{z}{\le \sum_j P_{ij}x_j\quad}{\forall i\in I}
\addConstraint{x_j}{\ge0\quad}{\forall j\in J}
\addConstraint{\sum_j x_j}{=1\quad}{}
\end{maxi}
\end{mdframed}

\end{example}

\end{document}

% max-flow min-cut
% SVM
% game theory
